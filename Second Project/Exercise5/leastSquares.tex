\documentclass[Second Project.tex]{subfiles}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\begin{document}

\subsection{ Μέθοδος Ελαχίστων Τετραγώνων }

Για την προσέγγιση με την μέθοδο των ελαχίστων τετραγώνων χρησιμοποιείται πολυώνυμο 10ου βαθμού. Η μέθοδος των 
ελαχίστων τετραγώνων προσεγγίζει ένα σύνολο σημείων εκπαίδευσης έτσι ώστε το άθροισμα των τετραγώνων του σφάλματος
σε κάθε σημείο να είναι ελάχιστο. Για παράδειγμα αν έχουμε $n$ σημεία εκπαίδευσης ($x_{i}, f_{i})$) και θέλουμε να τα
προσεγγίσουμε με ένα μοντέλο της μορφής $y = at + b$ πρέπει το 
\begin{equation*}
    \sum_{k=1}^{n} (f_{i} - ( at_{i} + b))^{2}
\end{equation*}
να γίνει ελάχιστο ως προς $a$ και $b$. Το σύστημα που προκύπτει από την παραπάνω απαίτηση δεν έχει πάντα λύση και 
επομένως υπάρχει ανάγκη για την εισαγωγή του όρου της κοντινότερης λύσης προς την ιδανική ( που δεν μπορεί να βρεθεί )
 λύση. Η κοντινότερη λύση ως προς την Ευκλείδια απόσταση μπορεί να βρέθει λύνοντας το παρακάτω σύστημα αντί το αρχικό
($Ax = b$) που δεν έχει λύση
\begin{equation*}
    A^{T}A\overline{x} = A^{T}b
\end{equation*}
Οι οποίες ονομάζονται και κανονικές εξισώσεις. Τέλος, για να μετρήσουμε την απόδοση του μοντέλου μας υπολογίζουμε το 
σφάλμα ως εξής 
\begin{equation*}
    r = b - A\overline{x}
\end{equation*}
Αν το διάνυσμα $r$ είναι το μηδενικό τότε έχουμε λύσει το αρχικό σύστημα $Ax = b$ ακριβώς. Αν όχι, το Ευκλείδιο μέτρο
του διανύσματος $r$ είναι μία μετρική για το σφάλμα στην λύση $\overline{x}$. Υπάρχουν τουλάχιστον τρεις μετρικές 
για να εκφράσουμε το μέγεθος του σφάλματος.
\newpage
\begin{itemize}
    \item Το Ευκλείδιο μέτρο
        \begin{center}
            $\norm{r} = \sqrt{r_{1}^{2} + \dots + r_{m}^{2}}$
        \end{center}
    \item Το τετραγωνικό σφάλμα (\textlatin{\textbf{Squared Error - SE}})
        \begin{center}
            $SE = r_{1}^2 + \dots + r_{m}^2$
        \end{center}
    \item \textlatin{\textbf{Root Mean Squared Error - RMSE}}
        \begin{center}
            $RMSE = \sqrt{SE/m} = \sqrt{(r_{1}^2 + \dots + r_{m}^2)/m}$
        \end{center}
\end{itemize}
Από τα οποία μπορούμε να συμπεράνουμε ότι αν ελαχιστοποιήσουμε το ένα ελαχιστοποιούνται και τα υπόλοιπα.
\par Στο αρχείο \textlatin{\textbf{leastSquares.py}} υπάρχουν τρεις συναρτήσεις. Η συνάρτηση 
\textlatin{\textit{least\_squares\_fit}} δέχεται ως ορίσματα τα σημεία εκπαίδευσης και τον βαθμό του πολυωνύμου με το
οποίο θα προσεγγιστούν τα σημεία εκπαίδευσης με την διαδικάσια που αναφέρθηκε παραπάνω, δηλαδή λύνοντας το σύστημα
$A^{T}A\overline{x} = A^{T}b$ και επιστρέφει την λύση $\overline{x}$. Στην συνέχεια, η συνάρτηση 
\textlatin{\textit{calculate\_polynomial}} υπολογίζει και επιστρέφει την τιμή του πολυωνύμου στην τιμή $x$ που δέχεται
σαν παράμετρο σε συνδυασμό με τον βαθμό του πολυωνύμου που έγινε η εκπαίδευση τον οποίο δέχεται κι αυτόν σαν
παράμετρο.  Τέλος, η συνάρτηση \textlatin{\textit{custom\_sin}} ορίζει αρχικά τα σημεία που αναφέρθηκαν στην παράγραφο
 της εισαγωγής της \textit{Άσκησης 1} και στην συνέχεια χρησιμοποιεί τις άλλες δύο συναρτήσεις για να προσεγγίσει την
  τιμή του ημιτόνου στο σημείο που δέχεται ως παράμετρο, αφού πρώτα το μεταφέρει στο διάστημα $[0,2\pi]$. Το μοντέλο 
επιλέχθηκε να είναι πολυώνυμο 10ου βαθμού καθώς είναι αυτό που ελαχιστοποιεί το \textlatin{\textbf{RMSE}} από όλα τα
μοντέλα που δοκιμάστηκαν ( πολυώνυμα βαθμού από 1 έως και 30 ).
\newpage
\end{document}